{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sitemaps\\\\sitemap1.xml',\n",
       " 'sitemaps\\\\sitemap2.xml',\n",
       " 'sitemaps\\\\sitemap3.xml',\n",
       " 'sitemaps\\\\sitemap4.xml',\n",
       " 'sitemaps\\\\sitemap5.xml']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sitemaps = glob.glob(\"sitemaps/*\")\n",
    "sitemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_url(url: str) -> bool:\n",
    "    \"\"\"\n",
    "    Matcher https://snl.no/abcabc, men ikke https://snl.no/abcabc/123123\n",
    "    \"\"\"\n",
    "    if re.match(\"^(https?:\\/\\/)?(www\\.)?snl\\.no\\/[^\\/]+\\/?$\", url):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def extract_valid_urls_from_sitemap(sitemap_path):\n",
    "    with open(sitemaps[0], \"r\", encoding=\"utf-8\") as f:\n",
    "        urls = bs4.BeautifulSoup(f.read()).find_all(\"loc\")\n",
    "        urls = [url.text for url in urls]\n",
    "        valid_urls = list(filter(is_valid_url, urls))\n",
    "\n",
    "    return valid_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\jorgen\\miniconda3\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      "100%|██████████| 5/5 [00:51<00:00, 10.33s/it]\n"
     ]
    }
   ],
   "source": [
    "all_urls = []\n",
    "for sitemap in tqdm.tqdm(sitemaps):\n",
    "    all_urls.extend(extract_valid_urls_from_sitemap(sitemap))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df = pd.DataFrame({\"url\": all_urls})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df.to_csv(\"snl_valid_urls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64c454191da68aae78a1958feb08cae1f714f347888099e6a2df204eeb298eaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
